# local_llm_2xy
llm with langchain

# directory

- references  
https://python.langchain.com/v0.2/docs/langserve/#server  
https://github.com/langchain-ai/langserve/tree/main/examples/local_llm

| name      |                                          link                                           | description                                                                                                       |
|:----------|:---------------------------------------------------------------------------------------:|:------------------------------------------------------------------------------------------------------------------|
| LLM       |       [server](xy_sample/llm/server.py),<br/>[client](xy_sample/llm/client.ipynb)       | LLMs Minimal example that reserves OpenAI and Anthropic chat models. Uses async, supports batching and streaming. |
| local LLM | [server](xy_sample/local_llm/server.py),<br/>[client](xy_sample/local_llm/client.ipynb) | local llm example                                                                                                 |